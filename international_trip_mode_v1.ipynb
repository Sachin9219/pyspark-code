{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba85e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark\\\\spark-3.0.0-preview-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3378f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('International_Trip_mode').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d4300a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-U21GL9O:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>International_Trip_mode</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x256d2454820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83120580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "#import findspark\n",
    "#findspark.init()\n",
    "#import pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import month\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import round,array,col,ntile,rank,asc,sum,desc,lag,lead,when,first,min,max,count\n",
    "# For Adding row number/index\n",
    "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkContext, SparkConf, keyword_only\n",
    "\n",
    "#from pyspark.sql import SQLContext, HiveContext, SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4870aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level2=spark.read.option('header','true').csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\test_output\\international_trip_nov\\*.csv\",inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc178169",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level2=trip_level2.withColumn('imsi_trip_id', concat(col('imsi'),lit('_'),col('trip_id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637ba416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trip_level2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637dec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trip_level2.toPandas().to_csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\test_output\\trip_level_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5219134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pa=spark.read.option('header','true').csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\PA.csv\",inferSchema='true')\n",
    "poi=spark.read.option('header','true').csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\POI.csv\",inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e8761ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_data_all =spark.read.json(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\PA.geojson\").drop('_corrupt_record').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2696df28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split,explode,regexp_replace,concat,window\n",
    "win_long = Window.partitionBy('pa_id','pa_centroid')\n",
    "pa_data_all1 = pa_data_all.withColumn('geometry1',col('geometry.coordinates')[0])\\\n",
    ".withColumn('geometry1',explode(col('geometry1')))\\\n",
    ".withColumn('pa_id',col('properties.pa_id'))\\\n",
    ".withColumn('pa_centroid',col('properties.pa_centroid')).select('pa_id','geometry1','pa_centroid')\\\n",
    ".withColumn('pa_long',col('geometry1')[0]).withColumn('pa_lat',col('geometry1')[1])\n",
    "\n",
    "pa_data_max = pa_data_all1.withColumn('max_long',max('pa_long').over(win_long)).filter(col('max_long')==col('pa_long')).dropDuplicates()\\\n",
    ".withColumnRenamed('geometry1','pa_max').withColumnRenamed('pa_lat','max_lat').select('pa_id','pa_centroid','pa_max','max_long','max_lat')\n",
    "pa_data_min = pa_data_all1.withColumn('min_long',min('pa_long').over(win_long)).filter(col('min_long')==col('pa_long')).dropDuplicates()\\\n",
    ".withColumnRenamed('geometry1','pa_min').withColumnRenamed('pa_lat','min_lat').select('pa_id','pa_centroid','pa_min','min_long','min_lat')\n",
    "\n",
    "#pa_data_max.filter(col('pa_id')=='P00000018030').show(30,False)\n",
    "#pa_data_min.filter(col('pa_id')=='P00000018030').show(30,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d58090",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_data_all.createOrReplaceTempView(\"patable\")\n",
    "#pa_data_all.printSchema()\n",
    "from shapely.geometry import Point, Polygon\n",
    "padf = pa_data_max.join(pa_data_min,['pa_id','pa_centroid']).dropDuplicates()\\\n",
    ".withColumn('pa_centroid1',regexp_replace(col('pa_centroid'),'POINT',''))\\\n",
    ".withColumn(\"cenlong_pa\", split(col(\"pa_centroid1\"), \" \").getItem(1)).withColumn(\"cenlat_pa\", split(col(\"pa_centroid1\"), \" \").getItem(2))\\\n",
    ".withColumn('cenlong_pa',regexp_replace(col('cenlong_pa'),'\\\\(',''))\\\n",
    ".withColumn('cenlat_pa',regexp_replace(col('cenlat_pa'),'\\\\)','')).drop('pa_centroid1','pa_max','pa_min')\n",
    "pa_id = padf.select('pa_id','max_long','max_lat','min_long','min_lat','cenlong_pa','cenlat_pa')\n",
    "#pa_id.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "103e786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "112dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_id1 = pa_id.select(\"max_long\",\"max_lat\",\"pa_id\").distinct()\n",
    "pa_id2 = pa_id.select(\"min_long\",\"min_lat\",\"pa_id\").distinct()\n",
    "pa_id3 = pa_id.select(\"cenlong_pa\",\"cenlat_pa\",\"pa_id\").distinct()\n",
    "poi_id1 =poi.select('lm_id','lm_latitude','lm_longtitude','Mode').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ed5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_arr = pa_id1.toPandas()\n",
    "max_arr1 = max_arr[['max_long', 'max_lat','pa_id']].values.tolist()\n",
    "min_arr = pa_id2.toPandas()\n",
    "min_arr1 = min_arr[['min_long', 'min_lat','pa_id']].values.tolist()\n",
    "cen_arr = pa_id3.toPandas()\n",
    "cen_arr1 = cen_arr[[\"cenlong_pa\",\"cenlat_pa\",\"pa_id\"]].values.tolist()\n",
    "poi_arr = poi_id1.toPandas()\n",
    "poi_arr1 = poi_arr[[\"lm_longtitude\",\"lm_latitude\",\"lm_id\"]].values.tolist()\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.spatial import cKDTree\n",
    "def ckdnearest(points):\n",
    "    k=1\n",
    "    nA = pd.DataFrame(points,columns=[\"long\",\"lat\"]).values.tolist()\n",
    "    btree = cKDTree(nA)\n",
    "    def Extract(lst):\n",
    "      return [(item[0],item[1]) for item in lst]\n",
    "    #max_arr1 = pd.DataFrame(max_arr,columns=['long','lat','pa_id'])\n",
    "    #max_arr1 = pa_id1.toPandas()\n",
    "    max_arr2 = Extract(max_arr1)\n",
    "    maxdist,idx = btree.query(max_arr2, k=1)\n",
    "    mindist_index1 = np.argmin(maxdist)\n",
    "    dist_arr1 = max_arr1[mindist_index1],maxdist[mindist_index1]\n",
    "    #return np.float(round(maxdist[mindist_index1]),2)\n",
    "    \n",
    "    #min_arr1 = pd.DataFrame(min_arr,columns=['long','lat','pa_id'])\n",
    "    #min_arr1 = pa_id2.toPandas()\n",
    "    min_arr2 = Extract(min_arr1)\n",
    "    mindist,idx = btree.query(min_arr2, k=1)\n",
    "    mindist_index2 = np.argmin(mindist)\n",
    "    dist_arr2 = min_arr1[mindist_index2],mindist[mindist_index2]\n",
    "    \n",
    "    #cen_arr1 = pd.DataFrame(cen_arr,columns=['long','lat','pa_id'])\n",
    "    #cen_arr1 = pa_id3.toPandas()\n",
    "    cen_arr2 = Extract(cen_arr1)\n",
    "    cendist,idx = btree.query(cen_arr2, k=1)\n",
    "    mindist_index3 = np.argmin(cendist)\n",
    "    dist_arr3 = cen_arr1[mindist_index3],cendist[mindist_index3]\n",
    "    \n",
    "    \n",
    "    zipped = [maxdist[mindist_index1]*111, mindist[mindist_index2]*111,cendist[mindist_index3]*111]\n",
    "    zipped1 = [max_arr1[mindist_index1],min_arr1[mindist_index2],cen_arr1[mindist_index3]]\n",
    "    df = pd.DataFrame(zipped1, columns=['long','lat','pa_id'])#,'local_cat'\n",
    "    df['distance'] =(zipped)\n",
    "    df1 = (df[df['distance'] == df['distance'].min()])[['pa_id','distance']]#,'local_cat'\n",
    "    \n",
    "    #poi_arr1 = pd.DataFrame(poi_arr,columns=['long','lat','lm_id'])\n",
    "    #poi_arr1 = poi_id1.toPandas()\n",
    "    poi_arr2 = Extract(poi_arr1)\n",
    "    poidist,idx = btree.query(poi_arr2, k=1)\n",
    "    mindist_index4 = np.argmin(poidist)\n",
    "    dist_arr4 = poi_arr1[mindist_index4],poidist[mindist_index4]\n",
    "    df_poi = pd.DataFrame([poi_arr1[mindist_index4]], columns=['long','lat','lm_id'])#,'lm_name','lm_sub_name'\n",
    "    df_poi['distance']=(poidist[mindist_index4]*111)\n",
    "    \n",
    "    if  (df1['distance'].values[0]<=5.0):\n",
    "        return  df1[['pa_id']].values.tolist()#df1[['local_cat']].apply(lambda x: str(x))\n",
    "    elif (df_poi['distance'].values[0]<=5.0):\n",
    "        return  df_poi[['lm_id']].values.tolist()\n",
    "    else :\n",
    "        return ['no category']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f55fda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47daf820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trip_level2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef59b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat,col,concat_ws\n",
    "\n",
    "exit_df1 = trip_level2.select('imsi_trip_id','exit_grid_longitude','exit_grid_latitude')\n",
    "\n",
    "\n",
    "exit_df2 = exit_df1.select('imsi_trip_id','exit_grid_longitude','exit_grid_latitude')\\\n",
    ".dropDuplicates().rdd.map(lambda x: (x[0], ([x[1], x[2]]))).groupByKey().mapValues(lambda _: ckdnearest((list(_))))\n",
    "\n",
    "#print(exit_df1.count())\n",
    "#print(clusterdf1.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6844411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- imsi_trip_id: string (nullable = true)\n",
      " |-- exit_Pa_Poi: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType,ArrayType\n",
    "deptSchema = StructType([       \n",
    "    StructField('imsi_trip_id', StringType(), True),\n",
    "    StructField('features', ArrayType(StringType()), True)])\n",
    "\n",
    "exit_df3 = spark.createDataFrame(exit_df2, schema = deptSchema).withColumn(\"exit_Pa_Poi\", col(\"features\").getItem(0).cast('String')).drop('features').dropDuplicates()\n",
    "#exit_df3 = exit_df3.filter(col('exit_Pa_Poi')!='no category')\n",
    "#exit_df3 = exit_df3.withColumn('exit_Pa_Poi',regexp_replace(col('exit_Pa_Poi'),'[','')).withColumn('exit_Pa_Poi',regexp_replace(col('exit_Pa_Poi'),']',''))\n",
    "exit_df3.printSchema()\n",
    "#exit_df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7854bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exit_df3 = exit_df3.withColumn('exit_Pa_Poi',regexp_replace(col('exit_Pa_Poi'),'[','')).withColumn('exit_Pa_Poi',regexp_replace(col('exit_Pa_Poi'),']',''))\n",
    "#exit_df3.show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde7cb14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entry_df1 = trip_level2.select('imsi_trip_id','entry_grid_longitude','entry_grid_latitude')\n",
    "\n",
    "entry_df2 = entry_df1.select('imsi_trip_id','entry_grid_longitude','entry_grid_latitude')\\\n",
    ".dropDuplicates().rdd.map(lambda x: (x[0], ([x[1], x[2]]))).groupByKey().mapValues(lambda _: ckdnearest((list(_))))\n",
    "\n",
    "#print(entry_df1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35ac22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2803c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- imsi_trip_id: string (nullable = true)\n",
      " |-- entry_Pa_Poi: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deptSchema = StructType([       \n",
    "    StructField('imsi_trip_id', StringType(), True),\n",
    "    StructField('features', ArrayType(StringType()), True)])\n",
    "\n",
    "entry_df3 = spark.createDataFrame(entry_df2, schema = deptSchema).withColumn(\"entry_Pa_Poi\", col(\"features\").getItem(0).cast('String')).drop('features').dropDuplicates()\n",
    "#entry_df3 = entry_df3.filter(col('entry_Pa_Poi')!='no category')\n",
    "#entry_df3 = entry_df3.withColumn('entry_Pa_Poi',regexp_replace(col('entry_Pa_Poi'),'[','')).withColumn('entry_Pa_Poi',regexp_replace(col('entry_Pa_Poi'),']',''))\n",
    "entry_df3.printSchema()\n",
    "#entry_df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d42818e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_data=exit_df3.join(entry_df3,['imsi_trip_id'],'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84b7f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "mode_data = mode_data.withColumn('entry_Pa_Poi',F.regexp_replace(\"entry_Pa_Poi\", \"\\\\[\", \"\"))\n",
    "mode_data = mode_data.withColumn('entry_Pa_Poi',F.regexp_replace(\"entry_Pa_Poi\", \"\\\\]\", \"\"))\n",
    "mode_data = mode_data.withColumn('exit_Pa_Poi',F.regexp_replace(\"exit_Pa_Poi\", \"\\\\[\", \"\"))\n",
    "mode_data = mode_data.withColumn('exit_Pa_Poi',F.regexp_replace(\"exit_Pa_Poi\", \"\\\\]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3adcc30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "816e88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99dda48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_poi_mode=spark.read.option('header','true').csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\Pa_poi_mode.csv\",inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89445d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_data1=mode_data.join(pa_poi_mode,(mode_data.exit_Pa_Poi==pa_poi_mode.pa_id),'left').withColumnRenamed('Mode','exit_Mode').distinct()\\\n",
    ".select('imsi_trip_id','exit_Pa_Poi','entry_Pa_Poi','exit_Mode') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cc95544",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_data2=mode_data1.join(pa_poi_mode,(mode_data1.entry_Pa_Poi==pa_poi_mode.pa_id),'left').withColumnRenamed('Mode','entry_Mode').distinct()\\\n",
    ".select('imsi_trip_id','exit_Mode','entry_Mode')\n",
    "\n",
    "#mode_data2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10456962",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_mode=trip_level2.join(mode_data2,['imsi_trip_id'],'left').distinct()\\\n",
    ".select('imsi','trip_id','trip_start_time','trip_end_time','exit_grid_id','exit_grid_name','entry_grid_id',\n",
    " 'entry_grid_name','exit_Mode','entry_Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fea7226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_mode.repartition(1).write.option(\"header\",True).mode(\"overwrite\").csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\test_output\\trip_mode_nov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9502c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96047ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41d7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7346b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
