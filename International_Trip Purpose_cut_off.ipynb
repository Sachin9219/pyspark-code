{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba85e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark\\\\spark-3.0.0-preview-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3378f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('International_Trip Purpose').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d4300a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-U21GL9O:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>International_Trip Purpose</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x155e6883190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec8265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import month\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import round,array,col,ntile,rank,asc,sum,desc,lag,lead,when,first,min,max,count\n",
    "# For Adding row number/index\n",
    "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
    "from pyspark.sql import Window\n",
    "\n",
    "\n",
    "#Import Library\n",
    "#import findspark\n",
    "#findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkContext, SparkConf, keyword_only\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#from pyspark.sql import SQLContext, HiveContext, SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a23cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level2=spark.read.option('header','true').csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\test_output\\trip_mode_nov\\*.csv\",inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef09643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0612b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Holiday_cal=spark.read.option('header','true').csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\Holiday_cal.csv\",inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e663fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level2=trip_level2.withColumn('imsi_trip_id', concat(col('imsi'),lit('_'),col('trip_id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1607eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holiday_cal.show(4),Holiday_cal.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739e41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trip_level2.select('imsi','trip_id','trip_start_time','trip_end_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45d9c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level3=trip_level2.where(~col('trip_start_time').contains(\"Trip_start_missing\") & ~col('trip_end_time').contains(\"Trip_end_missing\")).select('imsi','trip_id','trip_start_time','trip_end_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb593a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------------+-------------+\n",
      "|imsi|trip_id|trip_start_time|trip_end_time|\n",
      "+----+-------+---------------+-------------+\n",
      "+----+-------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_level3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae7b924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d815ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Holiday_cal=Holiday_cal.withColumn('date_id',to_date(Holiday_cal.date_id, 'dd-MM-yyyy'))\n",
    "#Holiday_cal=Holiday_cal.withColumn('month',month(Holiday_cal.date_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b914b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql import functions as F\n",
    "trip_level3=trip_level3.withColumn('trip_start_time',to_timestamp(col('trip_start_time'), 'dd-MM-yyyy HH:mm'))\\\n",
    "            .withColumn('trip_end_time',to_timestamp(col('trip_end_time'), 'dd-MM-yyyy HH:mm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82621023",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level3=trip_level3.withColumn('start_date',to_date(col('trip_start_time'), 'yyyy-MM-dd HH:mm:ss'))\\\n",
    "            .withColumn('end_date',to_date(col('trip_end_time'), 'yyyy-MM-dd HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b9ab87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level3=trip_level3.withColumn('DiffInSeconds',unix_timestamp(col('trip_end_time')) - unix_timestamp(col('trip_start_time'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75945b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level3=trip_level3.withColumn('trip_duration_min',round(col('DiffInSeconds')/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f461018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------------+-------------+----------+--------+-------------+-----------------+\n",
      "|imsi|trip_id|trip_start_time|trip_end_time|start_date|end_date|DiffInSeconds|trip_duration_min|\n",
      "+----+-------+---------------+-------------+----------+--------+-------------+-----------------+\n",
      "+----+-------+---------------+-------------+----------+--------+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_level3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ffb4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = trip_level3 \\\n",
    "  .withColumn('start_date1', F.col('start_date').cast('date')) \\\n",
    "  .withColumn('end_date1', F.col('end_date').cast('date'))\n",
    "\n",
    "trip_level4=trip_level3.withColumn('txnDt', F.explode(F.expr('sequence(start_date, end_date, interval 1 day)'))).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d5e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_level5=trip_level4.join(Holiday_cal.select('date_id'),(trip_level4.txnDt==Holiday_cal.date_id),'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3815c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract day of week from date in pyspark\n",
    "from pyspark.sql.functions import dayofweek\n",
    "\n",
    "df1 = trip_level5.withColumn('day_of_week',dayofweek(trip_level5.txnDt))\n",
    "#df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e22ae8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"Holiday\", when(col(\"date_id\").isNull(),lit(0)).otherwise(lit(1)))\n",
    "df1 = df1.withColumn(\"weekend\", when(col(\"day_of_week\")>5,lit(1)).otherwise(lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87bed0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df1.groupBy('imsi','trip_id','trip_start_time','trip_end_time','start_date','end_date','trip_duration_min').agg(sum('Holiday').alias('Holiday'),\n",
    "                                                                                                    sum(\"weekend\").alias(\"weekend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56ce76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_purpuse=trip_level2.join(df_agg.select('imsi','trip_id','Holiday','weekend','trip_duration_min'),['imsi','trip_id'],'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26af97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_purpuse1=trip_purpuse.withColumn(\"trip_purpuse\", when(col(\"Holiday\")!=0,'Holiday_trip')\\\n",
    "                                      .when(((col(\"Holiday\")==0) & (col('weekend')>0)),'Weekend_trip')\\\n",
    "                                      .when((col(\"trip_start_time\") == 'Trip_start_missing') | (col(\"trip_end_time\").isNull()),'')\\\n",
    "                                      .otherwise('Business_trip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba15026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_purpuse1=trip_purpuse1.select('imsi','trip_id','trip_start_time','trip_end_time','trip_duration_min','exit_grid_id','exit_grid_name','entry_grid_id','entry_grid_name',\n",
    " 'exit_Mode','entry_Mode','trip_purpuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "924bbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trip_purpuse1=trip_purpuse1.withColumn(\"trip_duration_min\", round(trip_purpuse1[\"trip_duration_min\"], 2).cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f40aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_purpuse1.repartition(1).write.option(\"header\",True).mode(\"overwrite\").csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\test_output\\trip_purpuse_nov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52443bc",
   "metadata": {},
   "source": [
    "### Trip cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b972632",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_purpuse=spark.read.option('header','true').csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\test_output\\trip_purpuse_nov\\*.csv\",inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2471e874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- imsi: string (nullable = true)\n",
      " |-- trip_id: integer (nullable = true)\n",
      " |-- trip_start_time: string (nullable = true)\n",
      " |-- trip_end_time: string (nullable = true)\n",
      " |-- trip_duration_min: string (nullable = true)\n",
      " |-- exit_grid_id: string (nullable = true)\n",
      " |-- exit_grid_name: string (nullable = true)\n",
      " |-- entry_grid_id: string (nullable = true)\n",
      " |-- entry_grid_name: string (nullable = true)\n",
      " |-- exit_Mode: string (nullable = true)\n",
      " |-- entry_Mode: string (nullable = true)\n",
      " |-- trip_purpuse: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_purpuse.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af60c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea30a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "trip_cut_off = trip_purpuse.withColumn(\"start_available\", when(col(\"trip_start_time\") == 'Trip_start_missing',0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6f30048",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_cut_off = trip_cut_off.withColumn(\"end_available\", when(col(\"trip_end_time\")== 'Trip_end_missing',0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86aa1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_cut_off = trip_cut_off.withColumn(\"incomplete_trip\", when((col(\"start_available\")==1) & (col(\"end_available\")==1),0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad4cdcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_cut_off.repartition(1).write.option(\"header\",True).mode(\"overwrite\").csv(r\"C:\\Users\\harin\\Desktop\\international\\Raw_Data\\test_output\\trip_cut_off_nov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1950ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bcda32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950bfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ba277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e0743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fab6423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577bec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b635661",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
